{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, Trainingdata- and Validationdata-Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 23512,
     "status": "ok",
     "timestamp": 1620482407776,
     "user": {
      "displayName": "Max S.",
      "photoUrl": "https://lh4.googleusercontent.com/-k4gYBVQolyU/AAAAAAAAAAI/AAAAAAAAAL4/pqtoeFCPcBs/s64/photo.jpg",
      "userId": "14906927569238660901"
     },
     "user_tz": -120
    },
    "id": "4IYmtuhpQ7Hh",
    "outputId": "5682f620-e50f-4fc6-b0cc-807c3e1b2f86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (256, 1, 9)\n",
      "Target shape: (256, 1)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import sklearn\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "#!/usr/bin/python\n",
    "import queue\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# Set seeds to make the experiment more reproducible.\n",
    "#from tensorflow import set_random_seed\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "\n",
    "train = pd.read_csv('TestData/train.csv',',')\n",
    "\n",
    "# train.describe()\n",
    "\n",
    "split_fraction = 0.70\n",
    "train_split = int(split_fraction * int(train.shape[0]))\n",
    "step = 1\n",
    "\n",
    "#past = 0\n",
    "#future = 8\n",
    "learning_rate = 0.0005\n",
    "batch = 256\n",
    "epochs = 100\n",
    "mean = 0\n",
    "std = 0\n",
    "\n",
    "def normalize(data, train_split):\n",
    "    global mean\n",
    "    global std\n",
    "    data_mean = data[:train_split].mean(axis=0)\n",
    "    mean = data_mean\n",
    "    data_std = data[:train_split].std(axis=0)\n",
    "    std = data_std\n",
    "    return (data - data_mean) / data_std\n",
    "\n",
    "titles = []\n",
    "for c in train.columns:\n",
    "    titles.append(c);\n",
    "    \n",
    "features = train[titles]\n",
    "features = normalize(features.values, train_split)\n",
    "features = pd.DataFrame(features)\n",
    "\n",
    "train_data = features.loc[0 : train_split - 1] #Training Data\n",
    "val_data = features.loc[train_split:] #Validation Data\n",
    "\n",
    "#start = past + future\n",
    "start = 0\n",
    "end = start + train_split\n",
    "\n",
    "x_train = train_data[[i for i in range(9)]].values\n",
    "y_train = features.iloc[start:end][[9]]\n",
    "\n",
    "#sequence_length = int(past / step)\n",
    "sequence_length = 1\n",
    "\n",
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch\n",
    ")\n",
    "\n",
    "label_start = train_split\n",
    "valRange = int(train.shape[0]) - train_split\n",
    "\n",
    "# x_val = val_data.iloc[[i for i in range(valRange)]].values\n",
    "x_val = val_data[[i for i in range(9)]].values\n",
    "# x_val = val_data.iloc[[i for i in range(49)]].values\n",
    "y_val = features.iloc[label_start:][[9]]\n",
    "\n",
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val,\n",
    "    y_val,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch\n",
    ")\n",
    "\n",
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "    \n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_loss(history, title):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(len(loss))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, \"b\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"r\", label=\"Validation loss\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def show_plot(plot_data, delta, title):\n",
    "    labels = [\"History\", \"True Future\", \"Model Prediction\"]\n",
    "    marker = [\".-\", \"rx\", \"go\"]\n",
    "    time_steps = list(range(-(plot_data[0].shape[0]), 0))\n",
    "    if delta:\n",
    "        future = delta\n",
    "    else:\n",
    "        future = 0\n",
    "\n",
    "    plt.title(title)\n",
    "    for i, val in enumerate(plot_data):\n",
    "        if i:\n",
    "            plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
    "        else:\n",
    "            plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
    "    plt.legend()\n",
    "    plt.xlim([time_steps[0], (future + 5) * 2])\n",
    "    plt.xlabel(\"Time-Step\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def denormalize(value):\n",
    "    data_mean = mean[9]\n",
    "    data_std = std[9]\n",
    "    return value*data_std+data_mean\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return 0.001\n",
    "    if lr > 0.004:\n",
    "        return lr - 0.0002\n",
    "    else:\n",
    "        if lr > 0.0004:\n",
    "            return lr - 0.000001\n",
    "        else:            \n",
    "            return 0.0001\n",
    "#     if epoch < 10:\n",
    "#         return lr\n",
    "#     else:\n",
    "#         if lr < 0.002:\n",
    "#             return lr - 0.00001\n",
    "#         else:\n",
    "#             return lr - 0.0015\n",
    "#     if lr < 0.002:\n",
    "#         return lr - 0.00001\n",
    "#     else:\n",
    "#         return lr\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
    "\n",
    "\n",
    "# array that holds every model --> models.append(...) is needed after every model definition\n",
    "models = []\n",
    "# array that holds every training output --> outs.append(...) is needed after every output definition\n",
    "outs = []\n",
    "# array that holds every modelcheckpoint callback --> modelcheckpoints.append(...) is needed after every modelcheckpoint callback definition\n",
    "modelcheckpoints = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables for Models and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 4000\n",
    "\n",
    "#define input layer for every model\n",
    "inputs = keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 - Dense with activation 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 9)]            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 9)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1, 10)             100       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1)              11        \n",
      "=================================================================\n",
      "Total params: 111\n",
      "Trainable params: 111\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\weick\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\weick\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: kerasModel1\\assets\n"
     ]
    }
   ],
   "source": [
    "modelckpt_callback_1 = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=\"kerasModel1/modelCheckpoint_1.h5\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "dropout1 = keras.layers.Dropout(0.2)(inputs)\n",
    "dense1 = keras.layers.Dense(10, activation='tanh', kernel_constraint=keras.constraints.MaxNorm(max_value=3, axis=0))(dropout1)\n",
    "dropout2 = keras.layers.Dropout(0.2)(dense1)\n",
    "outputs = keras.layers.Dense(1)(dropout2)\n",
    "model1 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model1.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8), loss=keras.losses.MeanAbsoluteError(), metrics=keras.metrics.MeanSquaredError())\n",
    "model1.summary()\n",
    "model1.save(\"kerasModel1\")\n",
    "models.append(model1)\n",
    "modelcheckpoints.append(modelckpt_callback_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Training Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5eaf68cb3fc48888dfa687d9d4b96b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out1 = widgets.Output(layout={'border': '1px solid black'})\n",
    "outs.append(out1)\n",
    "out1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 9)]            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 9)              0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 1, 10)             800       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1)              11        \n",
      "=================================================================\n",
      "Total params: 811\n",
      "Trainable params: 811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: kerasModel2\\assets\n"
     ]
    }
   ],
   "source": [
    "modelckpt_callback_2 = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=\"kerasModel2/modelCheckpoint_2.h5\",\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "dropout1 = keras.layers.Dropout(0.2)(inputs)\n",
    "dense1 = keras.layers.LSTM(10, return_sequences=True, kernel_constraint=keras.constraints.MaxNorm(max_value=3, axis=0))(dropout1)\n",
    "dropout2 = keras.layers.Dropout(0.2)(dense1)\n",
    "outputs = keras.layers.Dense(1)(dropout2)\n",
    "learning_rate = 0.01\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model2.compile(optimizer=keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.8), loss=keras.losses.MeanAbsoluteError(), metrics=keras.metrics.MeanSquaredError())\n",
    "model2.summary()\n",
    "model2.save(\"kerasModel2\")\n",
    "models.append(model2)\n",
    "modelcheckpoints.append(modelckpt_callback_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Training Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d176de289b430bb9f37156c0789ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "out2 = widgets.Output(layout={'border': '1px solid black'})\n",
    "outs.append(out2)\n",
    "out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading/Start of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exitFlag = 0\n",
    "\n",
    "switcherModels = {}\n",
    "i = 1\n",
    "for model in models:\n",
    "    switcherModels[i] = model\n",
    "    i += 1\n",
    "    \n",
    "switcherOuts = {}\n",
    "j = 1\n",
    "for output in outs:\n",
    "    switcherOuts[j] = output\n",
    "    j += 1\n",
    "    \n",
    "switcherCheckpoints = {}\n",
    "k = 1\n",
    "for checkpoint in modelcheckpoints:\n",
    "    switcherCheckpoints[k] = checkpoint\n",
    "    k += 1\n",
    "    \n",
    "numberOfModels = 2\n",
    "\n",
    "for i in range(numberOfModels):\n",
    "    index = i + 1\n",
    "    with switcherOuts.get(index):\n",
    "        currentModel = switcherModels.get(index)\n",
    "        history = currentModel.fit(\n",
    "            dataset_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=dataset_val,\n",
    "            callbacks=[es_callback,switcherCheckpoints.get(index), lr_scheduler]\n",
    "        )\n",
    "        \n",
    "        visualize_loss(history, \"Training and Validation loss\")\n",
    "        \n",
    "        for x, y in dataset_val.take(1):\n",
    "            show_plot(\n",
    "                [x[0][:, 0].numpy(), y[0].numpy(), currentModel.predict(x)[0]],\n",
    "                1,\n",
    "                \"Single Step Prediction\",\n",
    "            )\n",
    "        \n",
    "        for x, y in dataset_val.take(1):\n",
    "            predictionData = model.predict(x)\n",
    "            denormalized_predictionData = denormalize(predictionData)[0]\n",
    "            actualValue = y[0].numpy()\n",
    "            print(\"predicted denormalized:\", denormalized_predictionData)\n",
    "            print(\"   actual denormalized:\", denormalize(actualValue))\n",
    "            print(\"             predicted:\", predictionData[0])\n",
    "            print(\"                actual:\", actualValue)\n",
    "\n",
    "# class myThread (threading.Thread):\n",
    "#     def __init__(self, threadID, name, q):\n",
    "#         threading.Thread.__init__(self)\n",
    "#         self.threadID = threadID\n",
    "#         self.name = name\n",
    "#         self.q = q\n",
    "#     def run(self):\n",
    "#         print(\"Starting \" + self.name)\n",
    "#         train(self.name, self.q)\n",
    "#         print(\"Exiting \" + self.name)\n",
    "            \n",
    "# def train(threadName, q):\n",
    "#     while not exitFlag:\n",
    "#         queueLock.acquire()\n",
    "#         if not workQueue.empty():\n",
    "#             data = q.get()\n",
    "#             queueLock.release()\n",
    "#             print(\"%s processing %s\" % (threadName, data))\n",
    "#         else:\n",
    "#             queueLock.release()\n",
    "#         print(switcherOuts.get(q.get()))\n",
    "#         with switcherOuts.get(q.get()):\n",
    "#             switcherModels.get(q.get()).fit(\n",
    "#                 dataset_train,\n",
    "#                 epochs=epochs,\n",
    "#                 validation_data=dataset_val,\n",
    "#                 callbacks=[es_callback,modelckpt_callback, lr_scheduler]\n",
    "#             )\n",
    "\n",
    "# threadList = [\"Thread-1\", \"Thread-2\", \"Thread-3\"]\n",
    "\n",
    "# # define number of models to be processed\n",
    "# numberList = [];\n",
    "# numberOfModels = 2\n",
    "\n",
    "# # define maximum queue\n",
    "# maxQueue = 10\n",
    "\n",
    "# for i in range(numberOfModels):\n",
    "#     numberList.append(i+1)\n",
    "# queueLock = threading.Lock()\n",
    "# workQueue = queue.Queue(maxQueue)\n",
    "# threads = []\n",
    "# threadID = 1\n",
    "\n",
    "# # Create new threads\n",
    "# for tName in threadList:\n",
    "#     thread = myThread(threadID, tName, workQueue)\n",
    "#     thread.start()\n",
    "#     threads.append(thread)\n",
    "#     threadID += 1\n",
    "\n",
    "# # Fill the queue\n",
    "# queueLock.acquire()\n",
    "# for number in numberList:\n",
    "#     workQueue.put(number)\n",
    "# queueLock.release()\n",
    "\n",
    "# # Wait for queue to empty\n",
    "# while not workQueue.empty():\n",
    "#     pass\n",
    "\n",
    "# # Notify threads it's time to exit\n",
    "# exitFlag = 1\n",
    "\n",
    "# # Wait for all threads to complete\n",
    "# for t in threads:\n",
    "#     t.join()\n",
    "# print(\"Exiting Main Thread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Spielwiese.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
